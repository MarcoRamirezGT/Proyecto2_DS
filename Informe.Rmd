---
title: "Proyecto 2"
author: "Marco Ramirez, Estuardo Hernandez, Alfredo Quezada"
date: "2022-09-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prediccion de argumentos efectivos

El objetivo de este proyecto es clasificar los elementos argumentativos en la escritura de los estudiantes como "efectivos", "adecuados" o "ineficaces". Esto mediante los datos proporcionados por Kaggle.


### Situacion problematica

Partimos de la base, que una escrituta argumentativa ayuda a el crecimiento del pensamiento critito, dicho eso, solo el 13% de los catedraticos piden a sus alumnos 
que escriban de manera persuasiva, si quitamos ese 13% de alumnos que llegan a tener esa practica constante, resulta una cantidad de jovenes que no logran fomentar 
sus habilidades, si bien es cierto que a dia de hoy existe una cantidad abundante de herramientas en linea que permiten una retroalimentacion automatizada, no llega 
a similar ni siquiera igualar, la practica que se adquiere mediante el metodo tradicional. 

Por tanto, nos topamos con el problema de que no todos desarrollan una calidad aceptable de elementos argumentativos, desarrollo de ideas o la organizacion de ideas, por lo tanto, se estable una investigacion para determinar la calidad de los argumentos, en base a su efectividad. 


### Problema cientifico

Validadacion y calificacion de la efectividad de los argumentos encontrada en los representantes de Sexto a Doceavo grado. 

### Objetivos

**- Objetivos generales: ** 

1. Catalogar los argumentos en base a su efectividad.  


2. Determinar el tipo de discurso con mayor efectividad. 


**- Obetivos especificos: **

1. Identificar y catalogar discurosos como **Ineficaz** , **Adeacuado** o **Eficaz**


2. Identificar los sentimientos obtenidos en base a los discursos realizados. 


### Descripcion de los datos

```{r Analisis Exploratorio}

db<- read.csv('train.csv')


```

El conjunto de datos contiene ensayos argumentativos escritos por estudiantes estadounidenses en los grados 6-12. Estos ensayos fueron anotados por calificadores expertos para los elementos del discurso que se encuentran comúnmente en la escritura argumentativa:

-Lead: una introducción que comienza con una estadística, una cita, una descripción o algún otro dispositivo para captar la atención del lector y apuntar hacia la tesis.

-Position: una opinión o conclusión sobre la pregunta principal.

-Claim: un reclamo que respalda la posición.

-Counterclaim: una afirmación que refuta otra afirmación o da una razón opuesta a la posición.

-Rebuttal: una afirmación que refuta una contrademanda.

-Evidence: ideas o ejemplos que respaldan afirmaciones, reconvenciones o refutaciones.

-Concluding Statement: una declaración de conclusión que reafirma las afirmaciones.

#### Descripción del dataframe

-discourse_id: código de identificación para el elemento de discurso. Variable categórica.
-essay_id: código de identificación para la respuesta del ensayo. Variable categórica.
-discourse_text: texto del elemento del discurso. Variable categórica.
-discourse_type: etiqueta de clase del elemento de discurso. Variable categórica.
-discourse_effectiveness: calificación de la calidad del elemento del discurso, el objetivo. Variable categórica.

#### Representación gráfica de los datos

```{r}
plot(x = db$discourse_id)
plot(x = db$essay_id)
```

### Analisis Exploratorio

La base de datos cuenta con `r nrow(db)` filas y `r ncol(db)` columnas


```{r message=FALSE, warning=FALSE}
# Librerias necesarias

library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library(dplyr)
# Limpiamos el texto




```
#### 1. ¿Cuál es el tipo de discurso predominante?

```{r}

disType <- db %>% 
  group_by(db$discourse_type) %>% 
  tally()

colnames(disType)[1]<-'Tipo'
colnames(disType)[2]<-'Cantidad'

ggplot(data=disType, aes(x=reorder(Tipo,Cantidad), y=Cantidad,fill=Tipo)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Cantidad), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5)+
  labs(title="Cantidad de cada tipo de discurso",x='Tipo de discurso', y="Cantidad")+
  theme(legend.position="none")
```



Como se observa en la grafica anterior el tipo de discurso predominante es 'Evidence', el cual se refiere a ideas o ejemplos que respaldan afirmaciones, reconvenciones o refutaciones. Y en en segundo puesto se encuentra 'Claim', el cual es un reclamo que respalda alguna posicion. 


#### Cantidad de discursos categorizados como ineficaz, adecuado y eficaz

```{r}
cantType <- db %>% 
  group_by(db$discourse_effectiveness) %>% 
  tally()

colnames(cantType)[1]<-'Tipo'
colnames(cantType)[2]<-'Cantidad'

ggplot(data=cantType, aes(x=reorder(Tipo,Cantidad), y=Cantidad,fill=Tipo)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Cantidad), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5)+
  labs(title="Cantidad de cada efectividad de los discursos",x='Efectividad', y="Cantidad")+
  theme(legend.position="none")

```
<br />
Como se observa, los 3 tipos de efectividad no se encuentran balanceados, ademas, la efectividad predominante es 'Adequate' con una cantidad de '20977' discursos. 'Effective' con una cantidad de '9326' e 'Ineffective' con una cantidad de '6462'

#### Analisis del los discursos

##### Analisis del discurso sin limpieza
```{R warning=FALSE}

wordcloud(words = db$discourse_text, 
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))



```
< br />
Como se observa en la mayoria de discursos, la palabra con mayor frecuencia es estudiantes, luego people, y electoral, entre ellas.

Ahora veremos como se ve una nube de palabras con una limpieza de datos.

```{r warning=FALSE}

TextDoc <- Corpus(VectorSource(db$discourse_text))
#Replacing "/", "@" and "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
TextDoc <- tm_map(TextDoc, toSpace, "/")
TextDoc <- tm_map(TextDoc, toSpace, "@")
TextDoc <- tm_map(TextDoc, toSpace, "\\|")
# Convert the text to lower case
TextDoc <- tm_map(TextDoc, content_transformer(tolower))
# Remove numbers
TextDoc <- tm_map(TextDoc, removeNumbers)
# Remove english common stopwords
TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))
# Remove your own stop word
# specify your custom stopwords as a character vector
TextDoc <- tm_map(TextDoc, removeWords, c("like", "just", "get",'will','new','now','via','dont','one','can')) 
# Remove punctuations
TextDoc <- tm_map(TextDoc, removePunctuation)
# Eliminate extra white spaces
TextDoc <- tm_map(TextDoc, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc <- tm_map(TextDoc, stemDocument)

TextDoc_dtm <- TermDocumentMatrix(TextDoc)
dtm_m <- as.matrix(TextDoc_dtm)
 # Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
# Display the top 5 most frequent words
head(dtm_d)
# Plot the most frequent words
barplot(dtm_d[1:5,]$freq, las = 2, names.arg = dtm_d[1:5,]$word,
        col ="lightgreen", main ="Top 5 most frequent words",
        ylab = "Word frequencies")
set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```

<br /> 
Como se observa la palabra *Student* sigue predominando en los discursos de los estudiantes, asi como *people* y *vote*

##### Analisis de sentimiento en los discursos

```{r warning=FALSE}

syuzhet_vector <- get_sentiment(db$discourse_text, method="syuzhet")
# see the first row of the vector
head(syuzhet_vector)
# see summary statistics of the vector
summary(syuzhet_vector)

# bing
bing_vector <- get_sentiment(db$discourse_text, method="bing")
head(bing_vector)
summary(bing_vector)
#affin
afinn_vector <- get_sentiment(db$discourse_text, method="afinn")
head(afinn_vector)
summary(afinn_vector)

#compare the first row of each vector using sign function
rbind(
  sign(head(syuzhet_vector)),
  sign(head(bing_vector)),
  sign(head(afinn_vector))
)

d<-get_nrc_sentiment(db$discourse_text)
# head(d,10) - to see top 10 lines of the get_nrc_sentiment dataframe
head (d,10)
db$Enojo<- d$anger
db$Anticipacion<- d$anticipation
db$Disgusto<- d$disgust
db$Miedo<- d$fear
db$Felicidad<- d$joy
db$Tristeza<- d$sadness
db$Sorpresa<- d$surprise
db$Verdad<- d$trust
db$Negativo<- d$negative
db$Positivo<- d$positive



#transpose
td<-data.frame(t(d))
#The function rowSums computes column sums across rows for each level of a grouping variable.
td_new <- data.frame(rowSums(td[2:253]))
#Transformation and cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
#Plot One - count of words associated with each sentiment
quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment, ylab="count")+ggtitle("Survey sentiments")


#Plot two - count of words associated with each sentiment, expressed as a percentage
barplot(
  sort(colSums(prop.table(d[, 1:8]))), 
  horiz = TRUE, 
  cex.names = 0.7, 
  las = 1, 
  main = "Emotions in Text", xlab="Percentage"
)
```

<br/>
Como se observa en las graficas anterior, mas del 25% de los ensayos de los estudiantes logran transmitir la verdad. Mas del 15% logra transmitir anticipacion y mas del 10% logran transmitir felicidad, ademas, se observa que los sentimientos mas bajos son sorpresa, enojo y disgusto. 

```{r}
ineficiente<-subset(db, db$discourse_effectiveness=="Ineffective")
summary(ineficiente)
Efectivo<-subset(db, db$discourse_effectiveness=="Effective")
summary(Efectivo)
Adecuado<-subset(db, db$discourse_effectiveness=="Adequate")
summary(Adecuado)


```

```{r}
resumen<-data.frame(Categoria= c("Ineficiente","Adecuado","Eficiente"),
                    Enojo= c(mean(ineficiente$Enojo),mean(Adecuado$Enojo),mean(Efectivo$Enojo)),
                    Anticipacion= c(mean(ineficiente$Anticipacion),mean(Adecuado$Anticipacion),mean(Efectivo$Anticipacion)),
                    Disgusto= c(mean(ineficiente$Disgusto),mean(Adecuado$Disgusto),mean(Efectivo$Disgusto)),
                    Miedo= c(mean(ineficiente$Miedo),mean(Adecuado$Miedo),mean(Efectivo$Miedo)),
                    Felicidad= c(mean(ineficiente$Felicidad),mean(Adecuado$Felicidad),mean(Efectivo$Felicidad)),
                    Tristeza= c(mean(ineficiente$Tristeza),mean(Adecuado$Tristeza),mean(Efectivo$Tristeza)),
                    Sorpresa= c(mean(ineficiente$Sorpresa),mean(Adecuado$Sorpresa),mean(Efectivo$Sorpresa)),
                    Verdad= c(mean(ineficiente$Verdad),mean(Adecuado$Verdad),mean(Efectivo$Verdad)),
                    Negativo= c(mean(ineficiente$Negativo),mean(Adecuado$Negativo),mean(Efectivo$Negativo)),
                    Positivo= c(mean(ineficiente$Positivo),mean(Adecuado$Positivo),mean(Efectivo$Positivo))
                    
                    )

resumen
```
<br/>
Como se observa los argumentos mas eficientes es cuando poseen mas sentimiento, ya que como se observa anteriormente, la categoria de eficiente lidera en todos los sentimientos, dando a entender que el texto logra expresar de manera eficiente lo que el autor quiere explicar.

##### Cantidad de palabras

```{r}
require(stringr)

db<-read.csv("train.csv")

db$CantidadPalabras<-str_count(db$discourse_text, '\\w+')

ineficiente<-subset(db, db$discourse_effectiveness=="Ineffective")

Efectivo<-subset(db, db$discourse_effectiveness=="Effective")

Adecuado<-subset(db, db$discourse_effectiveness=="Adequate")

resumen<-data.frame(Categoria= c("Ineficiente","Adecuado","Eficiente"),
                    Promedio=c(mean(ineficiente$CantidadPalabras),mean(Efectivo$CantidadPalabras),mean(Adecuado$CantidadPalabras)))

ggplot(data=resumen, aes(x=reorder(Categoria,Promedio), y=Promedio,fill=Categoria)) +
  geom_bar(stat="identity", position=position_dodge())+
  geom_text(aes(label=Promedio), vjust=1.6, color="black",
            position = position_dodge(0.9), size=3.5)+
  labs(title="Promedio de palabras de cada categoria",x='Categoria', y="Promedio")+
  theme(legend.position="none")

```
<br/>
Como se observa en la grafica anterior, que un discurso o texto tenga mas cantidad de palabra, no significa que sera mas comprensible o en este caso mas eficiente. Evidenciando que cantidad no significa calidad.

### Conclusiones y hallazgos

1. Los argumentos con mejor escritura, uso de verbos y sobre todo uso correcto de las palabras, tienden a expresar mas sentimientos en su escritura, facilitando a los lectores comprender al autor.
2. Un argumento demasiado positivo no significa que sera eficiente.
3. Que un discurso tenga demasiadas palabras no signfica que sera eficiente o de mejor comprension.